{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install lightgbm shap imbalanced-learn\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# plt.style.use('seaborn')\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset (assuming SIF-2 is available as 'perovskites.csv')\n",
    "df = pd.read_excel(os.path.join('..', 'Data', 'Supplementary Information File 2 (SIF-2).xlsx'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data preprocessing\n",
    "def preprocess_data(df):\n",
    "    # Drop unnecessary columns\n",
    "    df = df.drop(['Compound', 'A', 'B', 'In literature'], axis=1)\n",
    "    \n",
    "    # One-hot encode Valence A\n",
    "    valence_a = pd.get_dummies(df['Valence A'], prefix='Valence_A')\n",
    "    df = pd.concat([df, valence_a], axis=1)\n",
    "    df = df.drop(['Valence A', 'Valence_A_4', 'Valence_A_5'], axis=1)\n",
    "    \n",
    "    # Convert target to categorical\n",
    "    df['Lowest distortion'] = df['Lowest distortion'].astype('category')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Valence A'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Project/ABO3_Perovskites_Classification/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Valence A'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m processed_df \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m processed_df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLowest distortion\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m processed_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLowest distortion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompound\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn literature\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# One-hot encode Valence A\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m valence_a \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mValence A\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValence_A\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, valence_a], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValence A\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValence_A_4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValence_A_5\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Project/ABO3_Perovskites_Classification/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Project/ABO3_Perovskites_Classification/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Valence A'"
     ]
    }
   ],
   "source": [
    "\n",
    "processed_df = preprocess_data(df)\n",
    "X = processed_df.drop('Lowest distortion', axis=1)\n",
    "y = processed_df['Lowest distortion']\n",
    "\n",
    "# Define features based on paper's final list\n",
    "features = [\n",
    "    'Valence_A_1', 'Valence_A_2', 'Valence_A_3',\n",
    "    'Radius A at XII', 'Radius A at VI',\n",
    "    'EN(A)', 'EN(B)',\n",
    "    'Bond length A-O', 'Bond length B-O',\n",
    "    'ΔENR', 'tG', 'τ', 'μ'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize LightGBM model\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    class_weight='balanced',\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_estimators=500,\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "\n",
    "# Stratified K-Fold Cross Validation with SMOTE\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "smote = SMOTE(random_state=RANDOM_STATE)\n",
    "\n",
    "cv_scores = []\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Apply SMOTE only to training data\n",
    "    X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train model\n",
    "    lgb_model.fit(X_res, y_res)\n",
    "    \n",
    "    # Evaluate\n",
    "    score = lgb_model.score(X_test, y_test)\n",
    "    cv_scores.append(score)\n",
    "\n",
    "print(f\"Cross-validation Accuracy: {np.mean(cv_scores):.3f} ± {np.std(cv_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Full model training with SMOTE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "lgb_model.fit(X_res, y_res)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "\n",
    "# Performance metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion Matrix\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=lgb_model.classes_,\n",
    "                yticklabels=lgb_model.classes_)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Feature Importance\n",
    "def plot_feature_importance(model, features):\n",
    "    importance = model.feature_importances_\n",
    "    indices = np.argsort(importance)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.bar(range(len(features)), importance[indices], align='center')\n",
    "    plt.xticks(range(len(features)), np.array(features)[indices], rotation=90)\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_importance(lgb_model, features)\n",
    "\n",
    "# SHAP Analysis\n",
    "def shap_analysis(model, X_sample):\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_sample)\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    shap.summary_plot(shap_values, X_sample, plot_type=\"bar\", class_names=model.classes_)\n",
    "    plt.show()\n",
    "    \n",
    "    for i, class_name in enumerate(model.classes_):\n",
    "        plt.figure(figsize=(12,6))\n",
    "        shap.summary_plot(shap_values[i], X_sample, plot_type=\"dot\", show=False)\n",
    "        plt.title(f\"SHAP Summary for {class_name}\")\n",
    "        plt.show()\n",
    "\n",
    "shap_analysis(lgb_model, X.sample(100, random_state=RANDOM_STATE))  # Use subset for speed\n",
    "\n",
    "# KDE Plots (assuming formation energy data is available)\n",
    "def plot_kde(df, target_col='Formation energy'):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for crystal_class in df['Lowest distortion'].unique():\n",
    "        subset = df[df['Lowest distortion'] == crystal_class]\n",
    "        sns.kdeplot(subset[target_col], label=crystal_class)\n",
    "    plt.xlabel('Formation Energy (eV)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('KDE of Formation Energy by Crystal Structure')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming formation energy data is available in original DF\n",
    "plot_kde(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
